{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from facenet_pytorch.models.mtcnn import PNet, RNet, ONet  # Import P-Net, R-Net, O-Net\n",
    "from facenet_pytorch import MTCNN\n",
    "import os\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Define fine-tuned P-Net, R-Net, and O-Net for finetuning\n",
    "class FinetunedMTCNN(MTCNN):\n",
    "#(self, image_size=160, margin=5, **kwargs): # use this after some time to improve the final results\n",
    "    def __init__(self, image_size=160, margin=15, **kwargs):\n",
    "        super(FinetunedMTCNN, self).__init__(**kwargs)\n",
    "\n",
    "        # Create your custom, finetuned P-Net, R-Net, O-Net here\n",
    "        self.pnet = PNet()\n",
    "        self.rnet = RNet()\n",
    "        self.onet = ONet()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Overriding forward pass if additional finetuning is needed\n",
    "        return super().forward(x)\n",
    "\n",
    "\n",
    "\n",
    "#new\n",
    "finetuned_mtcnn = FinetunedMTCNN(keep_all=True, device='cuda:0' if torch.cuda.is_available() else 'cpu', min_face_size=60, thresholds=[0.99, 0.99, 0.99])\n",
    "#new\n",
    "def find_euclidean_distance(src, dst):\n",
    "    return np.linalg.norm(src - dst)\n",
    "\n",
    "def alignment_procedure(img, left_eye, right_eye):    \n",
    "    left_eye_x, left_eye_y = left_eye\n",
    "    right_eye_x, right_eye_y = right_eye\n",
    "    \n",
    "    # Find the direction to rotate the image based on the eye coordinates\n",
    "    if left_eye_y > right_eye_y:\n",
    "        point_3rd = (right_eye_x, left_eye_y)\n",
    "        direction = -1  # Clockwise\n",
    "    else:\n",
    "        point_3rd = (left_eye_x, right_eye_y)\n",
    "        direction = 1  # Counter-clockwise\n",
    "    \n",
    "    # Calculate the length of the triangle edges\n",
    "    a = find_euclidean_distance(np.array(left_eye), np.array(point_3rd))\n",
    "    b = find_euclidean_distance(np.array(right_eye), np.array(point_3rd))\n",
    "    c = find_euclidean_distance(np.array(left_eye), np.array(right_eye))\n",
    "    \n",
    "    # Apply cosine rule to find the angle\n",
    "    if b != 0 and c != 0:  # Avoid division by zero\n",
    "        cos_a = (b**2 + c**2 - a**2) / (2 * b * c)\n",
    "        angle = np.arccos(cos_a)  # Angle in radians\n",
    "        angle = np.degrees(angle)  # Convert to degrees\n",
    "        \n",
    "        # Adjust the angle based on the rotation direction\n",
    "        if direction == -1:\n",
    "            angle = 90 - angle\n",
    "        \n",
    "        # Rotate the image using PIL\n",
    "        #img = Image.fromarray(img)\n",
    "        img = img.rotate(direction * angle, resample=Image.BICUBIC)\n",
    "        img = np.array(img)  # Convert back to numpy array\n",
    "        # aligned_img_pil = Image.fromarray(img)  # Convert back to PIL Image for saving\n",
    "        # aligned_img_pil.show()\n",
    "    return img\n",
    "# Function to perform face detection and store image paths with their cropped face regions\n",
    "\n",
    "def process_and_save_match_faces(image_folder, output_folder, mtcnn_model, margin=0):\n",
    "    # global match_photos_all\n",
    "    # match_photos_all = []\n",
    "    match_photos_paths = []\n",
    "    for filename in os.listdir(image_folder):\n",
    "        if filename.endswith(\".jpeg\"):\n",
    "            image_path = os.path.join(image_folder, filename)\n",
    "            image = Image.open(image_path)\n",
    "            boxes, confidences, landmarks = mtcnn_model.detect(image, landmarks=True)\n",
    "            if boxes is not None:\n",
    "                # Set a confidence threshold\n",
    "                threshold = 0.95\n",
    "                # Filter detected faces based on the confidence score\n",
    "                filtered_faces = [i for i, confidence in enumerate(confidences) if confidence > threshold]\n",
    "                #print(f\"Number of filtered faces: {len(filtered_faces)}\")\n",
    "                # Process each filtered face\n",
    "                for i in filtered_faces:\n",
    "                    box = boxes[i]  # Get the bounding box for the filtered face\n",
    "                    box = [int(b) for b in box]  # Ensure the box is in integer format\n",
    "                    # adding margin around the box\n",
    "                    # Apply margin to the bounding box\n",
    "                    x1 = max(0, box[0] - margin)  # Left\n",
    "                    y1 = max(0, box[1] - margin)  # Top\n",
    "                    x2 = min(image.width, box[2] + margin)  # Right\n",
    "                    y2 = min(image.height, box[3] + margin)  # Bottom\n",
    "                    # Crop the face from the image\n",
    "                    cropped_face = image.crop((x1, y1, x2, y2))\n",
    "                    if cropped_face is not None:\n",
    "                        # Get the landmarks (left and right eyes) for the current face\n",
    "                        left_eye = landmarks[i][0]  # Left eye coordinates for face i\n",
    "                        right_eye = landmarks[i][1]  # Right eye coordinates for face i\n",
    "                        # Align the cropped face using the eye coordinates\n",
    "                        aligned_face = alignment_procedure(cropped_face, left_eye, right_eye)\n",
    "                        final_face = Image.fromarray(aligned_face)\n",
    "                        face_output_path = os.path.join(output_folder, f'face_{filename}_{i}.jpeg')\n",
    "                        final_face.save(face_output_path)\n",
    "                        #photos.append(cropped_face)\n",
    "                        # Store the aligned face and the original image path\n",
    "                        #match_photos_all.append(aligned_face)\n",
    "                        #match_photos_paths.append(image_path)  # Store original image path\n",
    "    return match_photos_paths  # Return list of original image paths\n",
    "\n",
    "# # 2. Function to perform face detection, apply NMS, and save cropped face images\n",
    "# def process_and_save_faces(image_folder, output_folder, mtcnn_model):\n",
    "#     global photos\n",
    "#     photos = []\n",
    "#     for filename in os.listdir(image_folder):\n",
    "#         if filename.endswith(\".jpeg\"):\n",
    "#             image_path = os.path.join(image_folder, filename)\n",
    "#             image = Image.open(image_path)\n",
    "\n",
    "#             # Detect faces (with bounding boxes, probabilities, and landmarks)\n",
    "#             boxes, probs, landmarks = mtcnn_model.detect(image, landmarks=True)\n",
    "#             #print(f\"box{boxes} prob{probs} landmarks{landmarks}\")\n",
    "#             #print(boxes)\n",
    "#             #print(probs)\n",
    "#             #print(landmarks)\n",
    "#             if boxes is not None:\n",
    "#                 # Set a confidence threshold\n",
    "#                 threshold = 0.96\n",
    "\n",
    "#                 # Filter detected faces based on the confidence score\n",
    "#                 filtered_faces = [i for i, prob in enumerate(probs) if prob > threshold]\n",
    "\n",
    "#                 # Save cropped faces that pass the confidence threshold\n",
    "#                 for i in filtered_faces:\n",
    "#                     box = boxes[i]  # Get the bounding box for the filtered face\n",
    "#                     # Crop the face using the O-Net bounding box\n",
    "#                     cropped_face = image.crop(box)\n",
    "\n",
    "#                     # Save the cropped face image in the output folder\n",
    "#                     face_output_path = os.path.join(output_folder, f'face_{filename}_{i}.jpeg')\n",
    "#                     cropped_face.save(face_output_path)\n",
    "#                     photos.append(cropped_face)\n",
    "#                     # Optionally visualize the stages\n",
    "#                     #visualize_detection_stages(image, boxes, landmarks, f'Stage {i+1}')\n",
    "#     print(f\"number of match faces detected = {len(photos)}\")\n",
    "\n",
    "match_images_folder = r'D:\\Images\\Facial_reco_images\\Facial_reco_images\\Game'  #match photos\n",
    "output_folder_match = r'D:\\Images\\Facial_reco_images\\Facial_reco_images\\Maxi'  #saving match photos\n",
    "process_and_save_match_faces(match_images_folder, output_folder_match, finetuned_mtcnn, margin=50)\n",
    "\n",
    "# studio_images_folder = '/content/drive/My Drive/studio_photos'   #studio photos\n",
    "# output_folder_studio = '/content/drive/My Drive/output_studio'  #saving studio photos\n",
    "\n",
    "# Create the output directories if they don't exist\n",
    "# os.makedirs(output_folder_match, exist_ok=True)  # Create output_folder_match\n",
    "# os.makedirs(output_folder_studio, exist_ok=True)\n",
    "\n",
    "# 4. Process both match and studio images\n",
    "#process_and_save_faces(match_images_folder, finetuned_mtcnn)\n",
    "#process_and_save_faces(studio_images_folder, output_folder_studio, finetuned_mtcnn)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
