{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import easyocr #type:ignore\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from glob import glob\n",
    "from random import sample\n",
    "from PIL import Image, ImageFont, ImageDraw, ImageEnhance\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = easyocr.Reader(['en'], gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = r\"D:\\jersey_images\\2024-JUNE 13-MONDAY-TIME 1-FIELD 14-324-GAME-26471-TOURNAMENT-114.JPG\"\n",
    "reader.readtext(file, allowlist ='0123456789')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(file)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(file).resize((1280,1280))\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader.readtext(np.array(img), allowlist ='0123456789')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from paddleocr import PaddleOCR  \n",
    "\n",
    "# Initialize the DBNet model\n",
    "ocr = PaddleOCR(det_db_box_thresh=0.5, det_db_unclip_ratio=0.5, use_gpu=False)\n",
    "\n",
    "# Preprocessing Function\n",
    "def preprocess_image(image_path, target_size=(1280, 1280)):\n",
    "    image = cv2.imread(image_path)\n",
    "    original_image = image.copy()\n",
    "    \n",
    "    # Resize while maintaining aspect ratio\n",
    "    h, w, _ = image.shape\n",
    "    scale = min(target_size[0] / h, target_size[1] / w)\n",
    "    new_h, new_w = int(h * scale), int(w * scale)\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_LINEAR)\n",
    "    \n",
    "    # Add padding\n",
    "    padded_image = np.zeros((target_size[0], target_size[1], 3), dtype=np.uint8)\n",
    "    padded_image[:new_h, :new_w] = image\n",
    "\n",
    "    return original_image, padded_image\n",
    "\n",
    "# Draw bounding boxes with confidence\n",
    "def draw_boxes(image, boxes):\n",
    "    for box in boxes:\n",
    "        points = np.array(box[0], dtype=np.int32).reshape((-1, 2))\n",
    "        confidence = box[1]  # Confidence score\n",
    "        if isinstance(confidence, list):  # Ensure confidence is a float\n",
    "            confidence = confidence[0]\n",
    "        # Draw the bounding box\n",
    "        cv2.polylines(image, [points], isClosed=True, color=(0, 255, 255), thickness=2)\n",
    "        # Put the confidence score\n",
    "        x, y = points[0]\n",
    "        cv2.putText(image, f\"{confidence:.2f}\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "    return image\n",
    "\n",
    "# Crop and display detected regions\n",
    "def crop_detected_regions(image, boxes):\n",
    "    cropped_regions = []\n",
    "    for idx, box in enumerate(boxes):\n",
    "        points = np.array(box[0], dtype=np.int32).reshape((-1, 2))\n",
    "        x_min = np.min(points[:, 0])\n",
    "        y_min = np.min(points[:, 1])\n",
    "        x_max = np.max(points[:, 0])\n",
    "        y_max = np.max(points[:, 1])\n",
    "        cropped_region = image[y_min:y_max, x_min:x_max]\n",
    "        cropped_regions.append((idx, cropped_region))\n",
    "    return cropped_regions\n",
    "\n",
    "# Parameters\n",
    "image_path = r\"D:\\jersey_testing\\2024-JUNE 13-MONDAY-TIME 1-FIELD 1-324-GAME-26475-TOURNAMENT-88.JPG\"\n",
    "preprocessed_size = (640, 640)\n",
    "\n",
    "# Preprocessing\n",
    "original_image, preprocessed_image = preprocess_image(image_path, preprocessed_size)\n",
    "\n",
    "# Text Detection\n",
    "result = ocr.ocr(preprocessed_image, det=True, rec=False)\n",
    "\n",
    "# Get bounding boxes and confidence\n",
    "boxes_with_confidence = [(line[0], line[1]) for line in result[0]]\n",
    "print(boxes_with_confidence)\n",
    "\n",
    "# Visualize Results\n",
    "image_with_boxes = draw_boxes(original_image.copy(), boxes_with_confidence)\n",
    "\n",
    "# Crop Detected Regions\n",
    "cropped_regions = crop_detected_regions(original_image.copy(), boxes_with_confidence)\n",
    "\n",
    "# Save and Display Results\n",
    "cv2.imshow(\"Original Image\", original_image)\n",
    "cv2.imshow(\"Detected Text Regions\", cv2.resize(image_with_boxes, (800, 800)))  # Scale down for better display\n",
    "\n",
    "# Display Cropped Regions\n",
    "for idx, cropped in cropped_regions:\n",
    "    if cropped.size > 0:  # Ensure the cropped region is valid\n",
    "        cv2.imshow(f\"Cropped Region {idx}\", cropped)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025/01/03 14:51:15] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, use_mlu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='C:\\\\Users\\\\harsh.n/.paddleocr/whl\\\\det\\\\ch\\\\ch_PP-OCRv4_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.3, det_db_unclip_ratio=2.0, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='C:\\\\Users\\\\harsh.n/.paddleocr/whl\\\\rec\\\\ch\\\\ch_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='C:\\\\Users\\\\harsh.n\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\paddleocr\\\\ppocr\\\\utils\\\\ppocr_keys_v1.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=False, cls_model_dir='C:\\\\Users\\\\harsh.n/.paddleocr/whl\\\\cls\\\\ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, return_word_box=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, formula_algorithm='LaTeXOCR', formula_model_dir=None, formula_char_dict_path=None, formula_batch_num=1, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, formula=False, ocr=True, recovery=False, recovery_to_markdown=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='ch', det=True, rec=True, type='ocr', savefile=False, ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n",
      "[2025/01/03 14:51:16] ppocr WARNING: Since the angle classifier is not initialized, it will not be used during the forward process\n",
      "[[[730.0, 1592.0], [855.0, 1592.0], [855.0, 1710.0], [730.0, 1710.0]]]\n",
      "Line: [[730.0, 1592.0], [855.0, 1592.0], [855.0, 1710.0], [730.0, 1710.0]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from paddleocr import PaddleOCR\n",
    "\n",
    "# Initialize PaddleOCR for DBNet text detection\n",
    "ocr = PaddleOCR(det_db_box_thresh=0.3, det_db_unclip_ratio=2.0, use_gpu=False)\n",
    "\n",
    "# Function to draw bounding boxes\n",
    "def draw_detected_boxes(image, result):\n",
    "    for line in result[0]:\n",
    "        print(f\"Line: {line}\")  # Debugging: Inspect each line in result\n",
    "        box = line[0]  # Extract box coordinates\n",
    "        score = line[1]  # Extract confidence score\n",
    "\n",
    "        # Ensure score is a float\n",
    "        if isinstance(score, list):\n",
    "            score = score[0]  # Access the first element if it's a list\n",
    "\n",
    "        pts = np.array(box, dtype=np.int32).reshape((-1, 2))\n",
    "        # Draw the bounding box\n",
    "        cv2.polylines(image, [pts], isClosed=True, color=(0, 255, 255), thickness=2)\n",
    "        # Display confidence score\n",
    "        x, y = pts[0]\n",
    "        cv2.putText(image, f\"{float(score):.2f}\", (int(x), int(y) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "    return image\n",
    "\n",
    "# Load image\n",
    "image_path = r\"D:\\jersey_testing\\2024-JUNE 13-MONDAY-TIME 1-FIELD 1-324-GAME-26475-TOURNAMENT-88.JPG\"\n",
    "image = cv2.imread(image_path)\n",
    "if image is None:\n",
    "    print(\"Error: Image could not be loaded. Please check the path.\")\n",
    "    exit()\n",
    "\n",
    "# Run text detection\n",
    "result = ocr.ocr(image, det=True, rec=False)\n",
    "\n",
    "# Debugging: Print result structure\n",
    "print(result[0])  # Inspect detected boxes and confidence scores\n",
    "\n",
    "# Draw detected text boxes\n",
    "image_with_boxes = draw_detected_boxes(image.copy(), result)\n",
    "\n",
    "# Display results\n",
    "h, w, _ = image_with_boxes.shape\n",
    "scale = 800 / max(h, w)\n",
    "resized_image = cv2.resize(image_with_boxes, (int(w * scale), int(h * scale)))\n",
    "\n",
    "cv2.imshow(\"Detected Text Regions\", resized_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025/01/03 14:54:15] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, use_mlu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='C:\\\\Users\\\\harsh.n/.paddleocr/whl\\\\det\\\\ch\\\\ch_PP-OCRv4_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.3, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='C:\\\\Users\\\\harsh.n/.paddleocr/whl\\\\rec\\\\ch\\\\ch_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='C:\\\\Users\\\\harsh.n\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\paddleocr\\\\ppocr\\\\utils\\\\ppocr_keys_v1.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=False, cls_model_dir='C:\\\\Users\\\\harsh.n/.paddleocr/whl\\\\cls\\\\ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, return_word_box=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, formula_algorithm='LaTeXOCR', formula_model_dir=None, formula_char_dict_path=None, formula_batch_num=1, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, formula=False, ocr=True, recovery=False, recovery_to_markdown=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='ch', det=True, rec=True, type='ocr', savefile=False, ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n",
      "Error: Image could not be loaded. Please check the path.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 56\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Preprocess image\u001b[39;00m\n\u001b[0;32m     55\u001b[0m target_size \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m640\u001b[39m, \u001b[38;5;241m640\u001b[39m)\n\u001b[1;32m---> 56\u001b[0m preprocessed_image, scale, resized_shape \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Run text detection\u001b[39;00m\n\u001b[0;32m     59\u001b[0m result \u001b[38;5;241m=\u001b[39m ocr\u001b[38;5;241m.\u001b[39mocr(preprocessed_image, det\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, rec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[4], line 10\u001b[0m, in \u001b[0;36mpreprocess_image\u001b[1;34m(image, target_size)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_image\u001b[39m(image, target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m640\u001b[39m, \u001b[38;5;241m640\u001b[39m)):\n\u001b[1;32m---> 10\u001b[0m     original_h, original_w, _ \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n\u001b[0;32m     11\u001b[0m     scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(target_size[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m/\u001b[39m original_h, target_size[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m/\u001b[39m original_w)\n\u001b[0;32m     12\u001b[0m     new_h, new_w \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(original_h \u001b[38;5;241m*\u001b[39m scale), \u001b[38;5;28mint\u001b[39m(original_w \u001b[38;5;241m*\u001b[39m scale)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from paddleocr import PaddleOCR\n",
    "\n",
    "# Initialize PaddleOCR for DBNet text detection\n",
    "ocr = PaddleOCR(det_db_box_thresh=0.3, det_db_unclip_ratio=1.5, use_gpu=False)\n",
    "\n",
    "# Preprocess Image Function\n",
    "def preprocess_image(image, target_size=(640, 640)):\n",
    "    original_h, original_w, _ = image.shape\n",
    "    scale = min(target_size[0] / original_h, target_size[1] / original_w)\n",
    "    new_h, new_w = int(original_h * scale), int(original_w * scale)\n",
    "\n",
    "    resized_image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    # Add padding\n",
    "    padded_image = np.zeros((target_size[0], target_size[1], 3), dtype=np.uint8)\n",
    "    padded_image[:new_h, :new_w] = resized_image\n",
    "\n",
    "    return padded_image, scale, (new_h, new_w)\n",
    "\n",
    "# Draw Detected Boxes\n",
    "def draw_detected_boxes(image, result, scale, resized_shape, target_size):\n",
    "    original_h, original_w = image.shape[:2]\n",
    "    resized_h, resized_w = resized_shape\n",
    "\n",
    "    for line in result[0]:\n",
    "        box = line[0]  # Extract box coordinates\n",
    "        score = line[1]  # Extract confidence score\n",
    "\n",
    "        # Map the box coordinates back to the original image\n",
    "        box = np.array(box, dtype=np.float32)\n",
    "        box[:, 0] = box[:, 0] * (resized_w / target_size[1])\n",
    "        box[:, 1] = box[:, 1] * (resized_h / target_size[0])\n",
    "        box[:, 0] /= scale\n",
    "        box[:, 1] /= scale\n",
    "\n",
    "        # Draw the bounding box\n",
    "        pts = np.array(box, dtype=np.int32).reshape((-1, 2))\n",
    "        cv2.polylines(image, [pts], isClosed=True, color=(0, 255, 255), thickness=2)\n",
    "        # Display confidence score\n",
    "        x, y = pts[0]\n",
    "        cv2.putText(image, f\"{score:.2f}\", (int(x), int(y) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "\n",
    "    return image\n",
    "\n",
    "# Load image\n",
    "image_path = r\"D:\\jersey_testing\\your_image.jpg\"\n",
    "image = cv2.imread(image_path)\n",
    "if image is None:\n",
    "    print(\"Error: Image could not be loaded. Please check the path.\")\n",
    "    exit()\n",
    "\n",
    "# Preprocess image\n",
    "target_size = (640, 640)\n",
    "preprocessed_image, scale, resized_shape = preprocess_image(image, target_size)\n",
    "\n",
    "# Run text detection\n",
    "result = ocr.ocr(preprocessed_image, det=True, rec=False)\n",
    "\n",
    "# Draw detected text boxes\n",
    "image_with_boxes = draw_detected_boxes(image.copy(), result, scale, resized_shape, target_size)\n",
    "\n",
    "# Display results\n",
    "h, w, _ = image_with_boxes.shape\n",
    "resized_output = cv2.resize(image_with_boxes, (800, int(800 * h / w)))\n",
    "\n",
    "cv2.imshow(\"Detected Text Regions\", resized_output)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
