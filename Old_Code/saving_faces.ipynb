{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from facenet_pytorch.models.mtcnn import PNet, RNet, ONet\n",
    "from facenet_pytorch import MTCNN\n",
    "from facenet_pytorch import InceptionResnetV1\n",
    "import cv2\n",
    "from torch.nn.functional import normalize\n",
    "import pyodbc as odbc\n",
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "# Hyperparameters \n",
    "local_image_path = 'E:'  # Where your photos are stored locally\n",
    "db_prefix_path = '\\\\\\\\172.16.17.136\\\\PHOTO_ROOT' # Will be replaced with the database path\n",
    "min_face_size = 30 # Minimum faces you are allowing for the process eg. 30 (30*30 pixels)\n",
    "SERVER_NAME = '192.168.1.101' \n",
    "DRIVER_NAME = 'ODBC Driver 17 for SQL Server'\n",
    "DATABASE_NAME = 'AI_Face_Recognition'\n",
    "idle_sleeptime = 1200 # How many seconds do you want the while to sleep when there is no row found in the Queue data\n",
    "processing_sleeptime = 5 # How many seconds do you want the while to sleep when one game's process ends and another game's starts\n",
    "retry_count = 3 # How many number of tries are you allowing to each game when they face any error\n",
    "timestamp = 1200 # If any game has status InProgress, after how many seconds do you want to give that game a try\n",
    "studio_margin = 80 # How much more of the face do you want in the studio images eg. 80 (from each side it will take 80 more pixels)\n",
    "game_margin = 100 # How much more of the face do you want in the studio images eg. 80 (from each side it will take 80 more pixels)\n",
    "\n",
    "\n",
    "\n",
    "class FinetunedMTCNN(MTCNN):\n",
    "#(self, image_size=160, margin=5, **kwargs): # use this after some time to improve the final results\n",
    "    def __init__(self, **kwargs):\n",
    "        super(FinetunedMTCNN, self).__init__(**kwargs)\n",
    "        # Create your custom, finetuned P-Net, R-Net, O-Net here\n",
    "        self.pnet = PNet()\n",
    "        self.rnet = RNet()\n",
    "        self.onet = ONet()\n",
    "    def forward(self, x):\n",
    "        # Overriding forward pass if additional finetuning is needed\n",
    "        return super().forward(x)\n",
    "    \n",
    "\n",
    "facenet = InceptionResnetV1(pretrained='vggface2').eval() \n",
    "finetuned_mtcnn = FinetunedMTCNN(keep_all=True, device='cuda:0' if torch.cuda.is_available() else 'cpu', min_face_size=min_face_size)\n",
    "\n",
    "def find_euclidean_distance(src, dst):\n",
    "    \"\"\"provides Euclidean distance for Face Alignment process.\"\"\"\n",
    "    return np.linalg.norm(src - dst)\n",
    "\n",
    "def alignment_procedure(img, left_eye, right_eye): \n",
    "    \"\"\"function takes the cropped face and returns aligned photo.\"\"\"   \n",
    "    left_eye_x, left_eye_y = left_eye\n",
    "    right_eye_x, right_eye_y = right_eye\n",
    "    # Find the direction to rotate the image based on the eye coordinates\n",
    "    if left_eye_y > right_eye_y:\n",
    "        point_3rd = (right_eye_x, left_eye_y)\n",
    "        direction = -1  # Clockwise\n",
    "    else:\n",
    "        point_3rd = (left_eye_x, right_eye_y)\n",
    "        direction = 1  # Counter-clockwise\n",
    "    # Calculate the length of the triangle edges\n",
    "    a = find_euclidean_distance(np.array(left_eye), np.array(point_3rd))\n",
    "    b = find_euclidean_distance(np.array(right_eye), np.array(point_3rd))\n",
    "    c = find_euclidean_distance(np.array(left_eye), np.array(right_eye))\n",
    "    # Apply cosine rule to find the angle\n",
    "    if b != 0 and c != 0:  # Avoid division by zero\n",
    "        cos_a = (b**2 + c**2 - a**2) / (2 * b * c)\n",
    "        angle = np.arccos(cos_a)  # Angle in radians\n",
    "        angle = np.degrees(angle)  # Convert to degrees\n",
    "        # Adjust the angle based on the rotation direction\n",
    "        if direction == -1:\n",
    "            angle = 90 - angle\n",
    "        # Rotate the image using PIL\n",
    "        #img = Image.fromarray(img)\n",
    "        img = img.rotate(direction * angle, resample=Image.BICUBIC)\n",
    "        img = np.array(img)  # Convert back to numpy array\n",
    "        # aligned_img_pil = Image.fromarray(img)  # Convert back to PIL Image for saving\n",
    "        # aligned_img_pil.show()\n",
    "    return img\n",
    "\n",
    "def detect_align_embed_faces(path, mtcnn_model, margin=0):\n",
    "    \"\"\"function takes a photo and provides embedding for the same.\"\"\"\n",
    "    global error_occurred\n",
    "    cropped_photos = []\n",
    "    # Check if the file exists at the given path\n",
    "    if not os.path.exists(path):\n",
    "        error_occurred = True\n",
    "        return cropped_photos \n",
    "    try:\n",
    "        image = Image.open(path)\n",
    "        boxes, confidences, landmarks = mtcnn_model.detect(image, landmarks=True)\n",
    "        global photo_embeddings\n",
    "        photo_embeddings = []\n",
    "        if boxes is not None:\n",
    "            # Set a confidence threshold\n",
    "            threshold = 0.96\n",
    "            # Filter detected faces based on the confidence score\n",
    "            filtered_faces = [i for i, confidence in enumerate(confidences) if confidence > threshold]\n",
    "            # Process each filtered face\n",
    "            for i in filtered_faces:\n",
    "                box = boxes[i]  # Get the bounding box for the filtered face\n",
    "                box = [int(b) for b in box]  # Ensure the box is in integer format\n",
    "                # adding margin around the box\n",
    "                # Apply margin to the bounding box\n",
    "                x1 = max(0, box[0] - margin)  # Left\n",
    "                y1 = max(0, box[1] - margin)  # Top\n",
    "                x2 = min(image.width, box[2] + margin)  # Right\n",
    "                y2 = min(image.height, box[3] + margin)  # Bottom\n",
    "                # Crop the face from the image\n",
    "                cropped_face = image.crop((x1, y1, x2, y2))\n",
    "                if cropped_face is not None: \n",
    "                    # Get the landmarks (left and right eyes) for the current face\n",
    "                    left_eye = landmarks[i][0]  \n",
    "                    right_eye = landmarks[i][1] \n",
    "                    # Align the cropped face using the eye coordinates\n",
    "                    aligned_face = alignment_procedure(cropped_face, left_eye, right_eye)\n",
    "                    cropped_photos.append(aligned_face)\n",
    "            for photo in cropped_photos:\n",
    "                face_image = np.array(photo) # Convert the PIL image to a NumPy array\n",
    "                image = cv2.resize(face_image, (160, 160))  # Resize to 160x160 as required by FaceNet\n",
    "                image = torch.tensor(image).permute(2, 0, 1).unsqueeze(0).float() / 255.0  # Convert to tensor, normalize\n",
    "                embedding = facenet(image)  # Get the embedding\n",
    "                embedding = normalize(embedding, p=2, dim=1)  # L2 normalization of embeddings\n",
    "                embedding = embedding.detach().numpy()\n",
    "                if embedding is not None:\n",
    "                    photo_embeddings.append(embedding)  # Store the index and embedding\n",
    "        return photo_embeddings\n",
    "    except Exception as e:\n",
    "        # If there is an error opening or processing the image\n",
    "        print(f\"Error processing image at {path}: {e}\")\n",
    "        # Update game status to error\n",
    "        cur.execute(\"\"\"UPDATE AITournamentQueue SET Status = 'error' WHERE GameNumber = ?\"\"\", (queue_data[\"GameNumber\"],))\n",
    "        cnxn.commit()\n",
    "    return cropped_photos  # Continue with the next image\n",
    "\n",
    "def euclidean_distance(embedding1, embedding2):\n",
    "    return np.linalg.norm(embedding1 - embedding2)\n",
    "\n",
    "threshold = 0.8\n",
    "\n",
    "# Connection to database code:\n",
    "cnxn = odbc.connect('DRIVER='+DRIVER_NAME+'; \\\n",
    "                    SERVER='+SERVER_NAME+'; \\\n",
    "                    DATABASE = '+DATABASE_NAME+'; \\\n",
    "                    Uid=sa;Pwd=Masterly@123;')\n",
    "cur = cnxn.cursor()\n",
    "cur.execute(\"use AI_Face_Recognition\")\n",
    "\n",
    "\n",
    "error_occurred = False\n",
    "global count\n",
    "count = 206 #(total number of games which are in pending state.)\n",
    "\n",
    "while True:\n",
    "    queue_query = \"\"\"SELECT TOP 1 * FROM AITournamentQueue WHERE (Status IN('pending', 'error') AND RetryCount < ?) \n",
    "                        OR (Status = 'InProgress' AND DATEDIFF(SECOND, ProcessStartOn, CURRENT_TIMESTAMP) > ?)\"\"\"\n",
    "    cur.execute(queue_query, (retry_count, timestamp))\n",
    "    row_count = len(cur.fetchall())\n",
    "    if row_count == 0:\n",
    "        time.sleep(idle_sleeptime)\n",
    "    else:\n",
    "        try:\n",
    "            cur.execute(queue_query, (retry_count, timestamp))\n",
    "            queue_columns = [column[0] for column in cur.description]\n",
    "            queue_rows = cur.fetchall()\n",
    "            # This will fetch the games which have status pending\n",
    "            for queue_row in queue_rows:\n",
    "                count -= 1\n",
    "                queue_data = dict(zip(queue_columns, queue_row))\n",
    "                cur.execute(\"\"\"UPDATE AITournamentQueue \n",
    "                            SET ProcessStartOn = CURRENT_TIMESTAMP, \n",
    "                                Status = 'InProgress' WHERE GameNumber = ?\"\"\", (queue_data[\"GameNumber\"],))\n",
    "                cnxn.commit()\n",
    "                print(f\"Process begin for Game: {queue_data['GameNumber']}\")\n",
    "                # Below query will return the studio photos for the particular game\n",
    "                roster_query = \"\"\"\n",
    "                    SELECT * FROM CDPMediaCapture.dbo.Constellation \n",
    "                    WHERE PhotoType = 'Studio' AND TournamentID = ? AND MediaType = '.jpg' AND TeamKeys IN (?, ?) AND PhotoUse = ''\"\"\"\n",
    "                cur.execute(roster_query, (queue_data['TournamentID'], queue_data['TeamKey1'], queue_data['TeamKey2']))\n",
    "                roster_columns = [column[0] for column in cur.description]\n",
    "                roster_rows = cur.fetchall()\n",
    "                # for each studio photos, we will find embedding and adding it to the photoembedding table\n",
    "                for roster_row in roster_rows:\n",
    "                    roster_data = dict(zip(roster_columns, roster_row))\n",
    "                    imageStoredPath = roster_data['KioskHiresFile'].replace(db_prefix_path, local_image_path)\n",
    "                    photo_embeddings = detect_align_embed_faces(imageStoredPath, finetuned_mtcnn, margin=studio_margin)\n",
    "                    # Checking if the embedding is already present or not for the specific studio photo\n",
    "                    for embedding in photo_embeddings:\n",
    "                        cur.execute(\"\"\"\n",
    "                            SELECT COUNT(*) FROM PlayerPhotoEmbedding\n",
    "                            WHERE RosterID = ? AND TournamentID = ?\n",
    "                        \"\"\", (roster_data[\"RosterID\"], roster_data[\"TournamentID\"]))\n",
    "                        result = cur.fetchone()\n",
    "                        if result[0] > 0:\n",
    "                            pass\n",
    "                        else:\n",
    "                            cur.execute(\"\"\"\n",
    "                                INSERT INTO PlayerPhotoEmbedding (RosterID, TournamentID, SFaceEmbeddings, ImagePath, TeamKey, UpdatedOn, CreatedOn, ConstellationID)\n",
    "                                VALUES (?, ?, ?, ?, ?, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP, ?)\n",
    "                            \"\"\", (roster_data[\"RosterID\"], roster_data[\"TournamentID\"], embedding.tobytes(), imageStoredPath, roster_data[\"TeamKeys\"], roster_data[\"ConstellationID\"]))\n",
    "                            cnxn.commit()\n",
    "                print(\"Studio Photos Done\")\n",
    "                # Below query checks if there are already game photo embeddings exist in the GamePhotoEmbedding table, if then deletes them first then goes ahead again.\n",
    "                cur.execute(\"DELETE FROM GamePhotoDetail WHERE GameNumber = ?\", (queue_data[\"GameNumber\"],))\n",
    "                cur.execute(\"DELETE FROM GamePhotoEmbedding WHERE GameNumber = ?\", (queue_data[\"GameNumber\"],))\n",
    "                # Below query will provide the game photos respective to the game number\n",
    "                game_query = \"\"\"SELECT * FROM CDPMediaCapture.dbo.Constellation WHERE MediaType = '.jpg' AND GameNumber = ?\"\"\"\n",
    "                cur.execute(game_query, (queue_data[\"GameNumber\"],))\n",
    "                game_columns = [column[0] for column in cur.description]\n",
    "                game_rows = cur.fetchall()\n",
    "                # For each game photo, finding the number of faces and adding the details in the game photo detail table\n",
    "                for game_row in game_rows:\n",
    "                    game_data = dict(zip(game_columns, game_row))\n",
    "                    game_image_path = game_data['KioskHiresFile'].replace(db_prefix_path, local_image_path)\n",
    "                    photo_embeddings = detect_align_embed_faces(game_image_path, finetuned_mtcnn, margin=game_margin)\n",
    "                    id = cur.execute(\"\"\"\n",
    "                        INSERT INTO GamePhotoDetail (NuFaceDetected, ImagePath, RosterIDs, GameNumber, TournamentID, TournamentWeek, TournamentWeekNumber, GameDay, GameTime, GameField, GameDayNumber, GameTimeNumber, GameType, U, B, R, ConstellationID, IsMatch, IsGroupPhoto, IsTagged, IsAttempted, UpdatedOn, CreatedOn) OUTPUT inserted.GamePhotoDetailID\n",
    "                        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, NULL, NULL, NULL, NULL, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP)\n",
    "                    \"\"\", (len(photo_embeddings), game_image_path, None, game_data[\"GameNumber\"], game_data[\"TournamentID\"], game_data[\"TournamentWeek\"], game_data[\"TournamentWeekNumber\"], game_data[\"GameDay\"], game_data[\"GameTime\"], game_data[\"GameField\"], game_data[\"GameDayNumber\"], game_data[\"GameTimeNumber\"], game_data[\"GameType\"], game_data[\"U\"], game_data[\"B\"], game_data[\"R\"], game_data[\"ConstellationID\"])).fetchval()\n",
    "                    cnxn.commit()\n",
    "                    # For each game photo, adding the embedding and gamephotodetailid into the gamephotoembedding table\n",
    "                    for embedding in photo_embeddings:\n",
    "                        cur.execute(\"\"\"\n",
    "                            INSERT INTO GamePhotoEmbedding (GamePhotoDetailID, GFaceEmbedding, UpdatedOn, CreatedOn, GameNumber)\n",
    "                            VALUES (?, ?, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP, ?)\n",
    "                        \"\"\", (id, embedding.tobytes(), game_data['GameNumber']))\n",
    "                        cnxn.commit()\n",
    "                print(\"Game Photos Done.\")\n",
    "                cur.execute(\"\"\"SELECT PlayerEmbeddingId, SFaceEmbeddings, RosterID FROM PlayerPhotoEmbedding WHERE TeamKey IN (?, ?)\"\"\", (queue_data['TeamKey1'], queue_data['TeamKey2']))\n",
    "                player_columns = [column[0] for column in cur.description]\n",
    "                player_embeddings = [dict(zip(player_columns, row)) for row in cur.fetchall()]\n",
    "                # Process each studio embedding\n",
    "                for player in player_embeddings:\n",
    "                    s_embedding = np.frombuffer(player['SFaceEmbeddings'], dtype=np.float32).reshape(1, -1)\n",
    "                    # Fetch game embeddings with the same GameNumber\n",
    "                    cur.execute(\"\"\"\n",
    "                        SELECT GamePhotoEmbeddingId, GFaceEmbedding, GamePhotoDetailId \n",
    "                        FROM GamePhotoEmbedding \n",
    "                        WHERE GameNumber = ?\n",
    "                    \"\"\", (game_data['GameNumber'],))\n",
    "                    game_columns = [column[0] for column in cur.description]\n",
    "                    game_embeddings = [dict(zip(game_columns, row)) for row in cur.fetchall()]\n",
    "                    # Compare with relevant game embeddings\n",
    "                    for game in game_embeddings:\n",
    "                        g_embedding = np.frombuffer(game['GFaceEmbedding'], dtype=np.float32).reshape(1, -1)\n",
    "                        distance = euclidean_distance(s_embedding, g_embedding)\n",
    "                        if distance < threshold:\n",
    "                            cur.execute(\"\"\"\n",
    "                                        UPDATE GamePhotoDetail\n",
    "                                        SET MatchedFaces = MatchedFaces + 1,\n",
    "                                            RosterIDs = COALESCE(RosterIDs + ' ', '') + ?\n",
    "                                        WHERE GamePhotoDetailId = ?\n",
    "                                    \"\"\", (player['RosterID'], game['GamePhotoDetailId']))\n",
    "                            cnxn.commit()\n",
    "                # this function will try to match the studio photos with the game photos\n",
    "                print(\"Matching Task Done.\")\n",
    "                print(f\"Games Remaining: {count}\")\n",
    "                print(\"---------------------------------------------------------------------------------------------------------------------------------------\")  \n",
    "                if error_occurred is False:\n",
    "                    cur.execute(\"\"\"UPDATE AITournamentQueue SET Status = 'completed', ProcessEndOn = CURRENT_TIMESTAMP WHERE GameNumber = ?\"\"\", (queue_data['GameNumber'],))\n",
    "                    cnxn.commit()\n",
    "                else:\n",
    "                    cur.execute(\"\"\"UPDATE AITournamentQueue SET Status = 'error', ProcessEndOn = CURRENT_TIMESTAMP, RetryCount = RetryCount + 1 WHERE GameNumber = ?\"\"\", (queue_data['GameNumber'],))\n",
    "                    cnxn.commit()\n",
    "                    error_occurred = False\n",
    "                time.sleep(processing_sleeptime)\n",
    "\n",
    "        except Exception as e:\n",
    "            # Log the error for the overall loop\n",
    "            print(f\"Error in the main loop: {e}\")\n",
    "            cur.execute(\"\"\"UPDATE AITournamentQueue SET Status = 'error', ProcessEndOn = CURRENT_TIMESTAMP, RetryCount = RetryCount + 1 WHERE GameNumber = ?\"\"\", (queue_data['GameNumber'],))\n",
    "            cnxn.commit()\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming `game_rows` is a list of rows to process\n",
    "total_images = len(game_rows)  # Total number of game images\n",
    "\n",
    "# Wrap game_rows with tqdm for progress tracking\n",
    "for game_row in tqdm(game_rows, desc=\"Processing Game Images\", unit=\"image\", total=total_images):\n",
    "    game_data = dict(zip(game_columns, game_row))\n",
    "    game_image_path = game_data['KioskHiresFile'].replace(db_prefix_path, local_image_path)\n",
    "    \n",
    "    # Detect, align, and get embeddings\n",
    "    photo_embeddings = detect_align_embed_faces(game_image_path, finetuned_mtcnn, margin=game_margin)\n",
    "    \n",
    "    # Insert into GamePhotoDetail table\n",
    "    id = cur.execute(\"\"\"\n",
    "        INSERT INTO GamePhotoDetail (NuFaceDetected, ImagePath, RosterIDs, GameNumber, TournamentID, TournamentWeek, TournamentWeekNumber, GameDay, GameTime, GameField, GameDayNumber, GameTimeNumber, GameType, U, B, R, ConstellationID, IsMatch, IsGroupPhoto, IsTagged, IsAttempted, UpdatedOn, CreatedOn) OUTPUT inserted.GamePhotoDetailID\n",
    "        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, NULL, NULL, NULL, NULL, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP)\n",
    "    \"\"\", (len(photo_embeddings), game_image_path, None, game_data[\"GameNumber\"], game_data[\"TournamentID\"], game_data[\"TournamentWeek\"], game_data[\"TournamentWeekNumber\"], game_data[\"GameDay\"], game_data[\"GameTime\"], game_data[\"GameField\"], game_data[\"GameDayNumber\"], game_data[\"GameTimeNumber\"], game_data[\"GameType\"], game_data[\"U\"], game_data[\"B\"], game_data[\"R\"], game_data[\"ConstellationID\"])).fetchval()\n",
    "    cnxn.commit()\n",
    "    \n",
    "    # Insert embeddings into GamePhotoEmbedding table\n",
    "    for embedding in photo_embeddings:\n",
    "        cur.execute(\"\"\"\n",
    "            INSERT INTO GamePhotoEmbedding (GamePhotoDetailID, GFaceEmbedding, UpdatedOn, CreatedOn, GameNumber)\n",
    "            VALUES (?, ?, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP, ?)\n",
    "        \"\"\", (id, embedding.tobytes(), game_data['GameNumber']))\n",
    "        cnxn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "from facenet_pytorch.models.mtcnn import PNet, RNet, ONet\n",
    "from facenet_pytorch import MTCNN\n",
    "\n",
    "# 1. Define fine-tuned P-Net, R-Net, and O-Net for finetuning\n",
    "class FinetunedMTCNN(MTCNN):\n",
    "    def __init__(self, image_size=160, margin=15, **kwargs):\n",
    "        super(FinetunedMTCNN, self).__init__(**kwargs)\n",
    "\n",
    "        # Create your custom, fine-tuned P-Net, R-Net, O-Net here\n",
    "        self.pnet = PNet()\n",
    "        self.rnet = RNet()\n",
    "        self.onet = ONet()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Overriding forward pass if additional finetuning is needed\n",
    "        return super().forward(x)\n",
    "\n",
    "# Instantiate the fine-tuned MTCNN model\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "finetuned_mtcnn = FinetunedMTCNN(keep_all=True, device=device, min_face_size=60, thresholds=[0.6, 0.7, 0.7])\n",
    "\n",
    "# 2. Function to perform face detection, apply NMS, and save cropped face images\n",
    "def process_and_save_faces(image_folder, output_folder, mtcnn_model):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for filename in os.listdir(image_folder):\n",
    "        if filename.endswith(\".jpg\"):\n",
    "            image_path = os.path.join(image_folder, filename)\n",
    "            image = Image.open(image_path)\n",
    "\n",
    "            # Detect faces (with bounding boxes, probabilities, and landmarks)\n",
    "            boxes, probs, landmarks = mtcnn_model.detect(image, landmarks=True)\n",
    "\n",
    "            if boxes is not None:\n",
    "                # Set a confidence threshold\n",
    "                threshold = 0.96\n",
    "\n",
    "                # Filter detected faces based on the confidence score\n",
    "                filtered_faces = [i for i, prob in enumerate(probs) if prob > threshold]\n",
    "\n",
    "                # Save cropped faces that pass the confidence threshold\n",
    "                for i in filtered_faces:\n",
    "                    box = boxes[i]  # Get the bounding box for the filtered face\n",
    "                    cropped_face = image.crop(box)\n",
    "\n",
    "                    # Save the cropped face image in the output folder\n",
    "                    face_output_path = os.path.join(output_folder, f'face_{filename}_{i}.jpeg')\n",
    "                    cropped_face.save(face_output_path)\n",
    "\n",
    "# Specify your local directories\n",
    "match_images_folder = r'D:/Images/Facial_reco_images/Facial_reco_images/photo'\n",
    "output_folder_match = r'D:/Images/Facial_reco_images/Facial_reco_images/photo'\n",
    "# studio_images_folder = 'path/to/local/studio_images_folder'\n",
    "# output_folder_studio = 'path/to/local/output_folder_studio'\n",
    "\n",
    "# Create the output directories if they don't exist\n",
    "os.makedirs(output_folder_match, exist_ok=True)\n",
    "# os.makedirs(output_folder_studio, exist_ok=True)\n",
    "\n",
    "# Process both match and studio images\n",
    "process_and_save_faces(match_images_folder, output_folder_match, finetuned_mtcnn)\n",
    "# process_and_save_faces(studio_images_folder, output_folder_studio, finetuned_mtcnn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    try:\n",
    "        queue_query = \"SELECT TOP 10 * FROM AITournamentQueue WHERE Status = 'pending'\"\n",
    "        cur.execute(queue_query)\n",
    "        queue_columns = [column[0] for column in cur.description]\n",
    "        queue_rows = cur.fetchall()\n",
    "        # This will fetch the games which have status pending\n",
    "        for queue_row in queue_rows:\n",
    "            count -= 1\n",
    "            queue_data = dict(zip(queue_columns, queue_row))\n",
    "            # Update status to 'In Progress'\n",
    "            cur.execute(\"\"\"UPDATE AITournamentQueue \n",
    "                           SET ProcessStartOn = CURRENT_TIMESTAMP, \n",
    "                               Status = 'In Progress' \n",
    "                           WHERE GameNumber = ?\"\"\", (queue_data[\"GameNumber\"],))\n",
    "            cnxn.commit()\n",
    "            print(f\"Process begin for Game: {queue_data['GameNumber']}\")\n",
    "            try:\n",
    "                # Your main processing logic (roster_query, embedding generation, etc.)\n",
    "                roster_query = \"\"\"\n",
    "                    SELECT * FROM CDPMediaCapture.dbo.Constellation \n",
    "                    WHERE PhotoType = 'Studio' AND TournamentID = ? AND MediaType = '.jpg' \n",
    "                    AND TeamKeys IN (?, ?) AND PhotoUse = ''\"\"\"\n",
    "                cur.execute(roster_query, (queue_data['TournamentID'], queue_data['TeamKey1'], queue_data['TeamKey2']))\n",
    "                # (Rest of the code for processing roster_rows, embeddings, etc.)\n",
    "                # Update status to 'completed'\n",
    "                cur.execute(\"\"\"UPDATE AITournamentQueue \n",
    "                               SET Status = 'completed', ProcessEndOn = CURRENT_TIMESTAMP \n",
    "                               WHERE GameNumber = ?\"\"\", (queue_data['GameNumber'],))\n",
    "                cnxn.commit()\n",
    "            except Exception as e:\n",
    "                # Log the error\n",
    "                print(f\"Error processing game {queue_data['GameNumber']}: {e}\")\n",
    "                \n",
    "                # Update status to 'error' for this specific game\n",
    "                cur.execute(\"\"\"UPDATE AITournamentQueue \n",
    "                               SET Status = 'error', ProcessEndOn = CURRENT_TIMESTAMP \n",
    "                               WHERE GameNumber = ?\"\"\", (queue_data['GameNumber'],))\n",
    "                cnxn.commit()\n",
    "\n",
    "            print(\"---------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "    except Exception as e:\n",
    "        # Log the error for the overall loop\n",
    "        print(f\"Error in the main loop: {e}\")\n",
    "        break\n",
    "    finally:\n",
    "        # Ensure that the status of all remaining games is set to 'error'\n",
    "        cur.execute(\"\"\"UPDATE AITournamentQueue \n",
    "                       SET Status = 'error', ProcessEndOn = CURRENT_TIMESTAMP \n",
    "                       WHERE Status = 'In Progress'\"\"\")\n",
    "        cnxn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def detect_align_embed_faces(path, mtcnn_model, margin=0):\n",
    "    \"\"\"Function takes a photo and provides embedding for the same.\"\"\"\n",
    "    cropped_photos = []\n",
    "    \n",
    "    # Check if the file exists at the given path\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Error: Image not found at path {path}\")\n",
    "        # Assuming `queue_data[\"GameNumber\"]` is available here, update the status to error\n",
    "        cur.execute(\"\"\"\n",
    "            UPDATE AITournamentQueue \n",
    "            SET Status = 'error', ProcessEndOn = CURRENT_TIMESTAMP \n",
    "            WHERE GameNumber = ?\n",
    "        \"\"\", (queue_data[\"GameNumber\"],))  # This assumes queue_data is available\n",
    "        cnxn.commit()\n",
    "        return cropped_photos  # Return empty to continue processing the next photo\n",
    "    \n",
    "    try:\n",
    "        image = Image.open(path)  # Try to open the image\n",
    "        # Continue with the rest of the image processing (cropping, embedding, etc.)\n",
    "        # This part remains as it was before\n",
    "        # Example (replace with your actual code):\n",
    "        # cropped_photos = some_image_processing_function(image, mtcnn_model, margin)\n",
    "        pass  # Replace with your actual image processing logic\n",
    "\n",
    "    except Exception as e:\n",
    "        # If there is an error opening or processing the image\n",
    "        print(f\"Error processing image at {path}: {e}\")\n",
    "        # Update game status to error\n",
    "        cur.execute(\"\"\"\n",
    "            UPDATE AITournamentQueue \n",
    "            SET Status = 'error', ProcessEndOn = CURRENT_TIMESTAMP \n",
    "            WHERE GameNumber = ?\n",
    "        \"\"\", (queue_data[\"GameNumber\"],))\n",
    "        cnxn.commit()\n",
    "        \n",
    "    return cropped_photos  # Continue with the next image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_align_embed_faces(image_path, output_folder, mtcnn_model, margin=0):\n",
    "    \"\"\"function takes a photo and provides embedding for the same.\"\"\"\n",
    "    cropped_photos = []\n",
    "    image = Image.open(image_path)\n",
    "    boxes, confidences, landmarks = mtcnn_model.detect(image, landmarks=True)\n",
    "    global photo_embeddings\n",
    "    photo_embeddings = []\n",
    "    if boxes is not None:\n",
    "        threshold = 0.96\n",
    "        filtered_faces = [i for i, confidence in enumerate(confidences) if confidence > threshold]\n",
    "        for i in filtered_faces:\n",
    "            box = boxes[i]  \n",
    "            box = [int(b) for b in box]  \n",
    "            x1 = max(0, box[0] - margin)  \n",
    "            y1 = max(0, box[1] - margin)\n",
    "            x2 = min(image.width, box[2] + margin) \n",
    "            y2 = min(image.height, box[3] + margin)  \n",
    "            cropped_face = image.crop((x1, y1, x2, y2))\n",
    "            if cropped_face is not None: \n",
    "                left_eye = landmarks[i][0]  \n",
    "                right_eye = landmarks[i][1] \n",
    "                aligned_face = alignment_procedure(cropped_face, left_eye, right_eye)\n",
    "                face_output_path = os.path.join(output_folder, f'A_{i}.jpg')\n",
    "                aligned_face.save(face_output_path)\n",
    "                cropped_photos.append(aligned_face)\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Initialize a global counter for sequential naming\n",
    "global_count = 1\n",
    "def detect_align_embed_faces(image_path, output_folder, mtcnn_model, roster_id, margin=0):\n",
    "    global global_count  # Use the global counter for naming\n",
    "    cropped_photos = []\n",
    "    image = Image.open(image_path)\n",
    "    boxes, confidences, landmarks = mtcnn_model.detect(image, landmarks=True)\n",
    "    global photo_embeddings\n",
    "    photo_embeddings = []\n",
    "    if boxes is not None:\n",
    "        threshold = 0.96\n",
    "        filtered_faces = [i for i, confidence in enumerate(confidences) if confidence > threshold]\n",
    "        roster_folder = os.path.join(output_folder, str(roster_id))\n",
    "        os.makedirs(roster_folder, exist_ok=True)\n",
    "        for i in filtered_faces:\n",
    "            box = boxes[i]\n",
    "            box = [int(b) for b in box]\n",
    "            x1 = max(0, box[0] - margin)\n",
    "            y1 = max(0, box[1] - margin)\n",
    "            x2 = min(image.width, box[2] + margin)\n",
    "            y2 = min(image.height, box[3] + margin)\n",
    "            cropped_face = image.crop((x1, y1, x2, y2))\n",
    "            if cropped_face is not None:\n",
    "                left_eye = landmarks[i][0]\n",
    "                right_eye = landmarks[i][1]\n",
    "                aligned_face = alignment_procedure(cropped_face, left_eye, right_eye)\n",
    "                face_name = f'A{global_count}.jpg'\n",
    "                face_output_path = os.path.join(roster_folder, face_name)\n",
    "                aligned_face.save(face_output_path)\n",
    "                global_count += 1    \n",
    "    return cropped_photos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from facenet_model import FaceNetModel  # Replace with your actual FaceNet implementation\n",
    "from utils import load_image, save_image  # Utility functions for loading/saving images\n",
    "\n",
    "# Load FaceNet model\n",
    "facenet = FaceNetModel()\n",
    "\n",
    "# Threshold for matching\n",
    "threshold = 0.6  # Adjust based on your dataset\n",
    "\n",
    "# Paths\n",
    "studio_folder = \"path_to_studio_photos\"\n",
    "game_folder = \"path_to_game_photos\"\n",
    "output_folder = \"path_to_store_results\"\n",
    "\n",
    "# Iterate over studio photos\n",
    "for studio_filename in os.listdir(studio_folder):\n",
    "    studio_path = os.path.join(studio_folder, studio_filename)\n",
    "    studio_image = load_image(studio_path)\n",
    "    \n",
    "    # Get embedding for the studio photo\n",
    "    studio_embedding = facenet.get_embedding(studio_image)\n",
    "    \n",
    "    # Create an output folder for the studio photo\n",
    "    studio_output_folder = os.path.join(output_folder, os.path.splitext(studio_filename)[0])\n",
    "    os.makedirs(studio_output_folder, exist_ok=True)\n",
    "    \n",
    "    # Store the studio photo\n",
    "    save_image(studio_image, os.path.join(studio_output_folder, studio_filename))\n",
    "    \n",
    "    # Compare with game photos\n",
    "    for game_filename in os.listdir(game_folder):\n",
    "        game_path = os.path.join(game_folder, game_filename)\n",
    "        game_image = load_image(game_path)\n",
    "        \n",
    "        # Get embedding for the game photo\n",
    "        game_embedding = facenet.get_embedding(game_image)\n",
    "        \n",
    "        # Calculate Euclidean distance\n",
    "        distance = np.linalg.norm(studio_embedding - game_embedding)\n",
    "        \n",
    "        # Check if the game photo matches\n",
    "        if distance < threshold:\n",
    "            # Store the game photo in the same folder as the studio photo\n",
    "            save_image(game_image, os.path.join(studio_output_folder, game_filename))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
